{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, random\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from itertools import combinations \n",
    "import re, copy\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdsd_labeled_filepaths = glob('/media/dmlab/My Passport/DATA/BenchmarkDataset/MDSD/*_labeled_*.csv')\n",
    "mdsd_unlabeled_filepaths = glob('/media/dmlab/My Passport/DATA/BenchmarkDataset/MDSD/*_unlabeled_*.csv')\n",
    "save_dir = '/media/dmlab/My Passport/DATA/cross-domain/data'\n",
    "if not os.path.exists(save_dir): os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4,000 unlabeled reviews per domain\n",
    "* 2,000 labeled reviews per domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[books] Droped 477734 rows having duplicated text\n",
      "[dvd] Droped 39540 rows having duplicated text\n",
      "[electronics] Droped 2213 rows having duplicated text\n",
      "[kitchen] Droped 1218 rows having duplicated text\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_unlabeled.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_labeled.json\n"
     ]
    }
   ],
   "source": [
    "def concat_dataframes(filepaths, drop_duplicates=True, sample_num=4000):\n",
    "    dfs = []\n",
    "    for filepath in filepaths:\n",
    "        df = pd.read_csv(filepath)\n",
    "        domain = os.path.basename(filepath).split('_')[0]\n",
    "        df['domain'] = domain\n",
    "        original_len = len(df)\n",
    "        if drop_duplicates:\n",
    "            df.drop_duplicates(['text'], keep='last', inplace=True)   # 중복된 텍스트 제거\n",
    "            print('[{}] Droped {} rows having duplicated text'.format(domain, original_len-len(df)))\n",
    "        if sample_num is not None:\n",
    "            df = df.sample(n=sample_num)   # 4000개 데이터만 랜덤하게 선택\n",
    "        dfs.append(df)\n",
    "    concat_df = pd.concat(dfs)\n",
    "    concat_df = shuffle(concat_df)   # Shuffle\n",
    "    concat_df.reset_index(inplace=True)   # Reset index\n",
    "    return concat_df\n",
    "\n",
    "unlabeled_df = concat_dataframes(mdsd_unlabeled_filepaths)\n",
    "filepath = os.path.join(save_dir, 'MDSD_unlabeled.json')\n",
    "unlabeled_df.to_json(filepath)\n",
    "print('Created {}'.format(filepath))\n",
    "\n",
    "labeled_df = concat_dataframes(mdsd_labeled_filepaths, drop_duplicates=False, sample_num=None)\n",
    "filepath = os.path.join(save_dir, 'MDSD_labeled.json')\n",
    "labeled_df.to_json(filepath)\n",
    "print('Created {}'.format(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>366</td>\n",
       "      <td>Elaine Pagels is a wonderful writer. Her expla...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1024</td>\n",
       "      <td>I baked six loaves in this machine. I have bee...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>548</td>\n",
       "      <td>I BOUGHT THIS LIKE A IPOD BUT ITS BETTER I HAV...</td>\n",
       "      <td>positive</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>675</td>\n",
       "      <td>These are called \"Fruit Bowl\" but they are the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1098</td>\n",
       "      <td>Corkscrew has a nice heavy duty feel and does ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>156</td>\n",
       "      <td>This soap dish is beautiful, practical and stu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>462</td>\n",
       "      <td>WE ARE HALFWAY THROUGH THE FRIENDS SERIES...5 ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>dvd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>314</td>\n",
       "      <td>I was a little hesitant to spend over $10 for ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>635</td>\n",
       "      <td>Excellent item, very powerful and stylish. Wou...</td>\n",
       "      <td>positive</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>519</td>\n",
       "      <td>this is a good cartoon for competition with ro...</td>\n",
       "      <td>positive</td>\n",
       "      <td>dvd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label  \\\n",
       "0       366  Elaine Pagels is a wonderful writer. Her expla...  positive   \n",
       "1      1024  I baked six loaves in this machine. I have bee...  negative   \n",
       "2       548  I BOUGHT THIS LIKE A IPOD BUT ITS BETTER I HAV...  positive   \n",
       "3       675  These are called \"Fruit Bowl\" but they are the...  positive   \n",
       "4      1098  Corkscrew has a nice heavy duty feel and does ...  negative   \n",
       "...     ...                                                ...       ...   \n",
       "7995    156  This soap dish is beautiful, practical and stu...  positive   \n",
       "7996    462  WE ARE HALFWAY THROUGH THE FRIENDS SERIES...5 ...  positive   \n",
       "7997    314  I was a little hesitant to spend over $10 for ...  positive   \n",
       "7998    635  Excellent item, very powerful and stylish. Wou...  positive   \n",
       "7999    519  this is a good cartoon for competition with ro...  positive   \n",
       "\n",
       "           domain  \n",
       "0           books  \n",
       "1         kitchen  \n",
       "2     electronics  \n",
       "3         kitchen  \n",
       "4         kitchen  \n",
       "...           ...  \n",
       "7995      kitchen  \n",
       "7996          dvd  \n",
       "7997      kitchen  \n",
       "7998      kitchen  \n",
       "7999          dvd  \n",
       "\n",
       "[8000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df = pd.read_json(os.path.join(save_dir, 'MDSD_labeled.json'))\n",
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12429</td>\n",
       "      <td>the ease and timelyness of the product was ver...</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813196</td>\n",
       "      <td>I'm a man about to turn 50 with 4 yr. olds twi...</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>527488</td>\n",
       "      <td>There is tons to do in Washington DC and despi...</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701823</td>\n",
       "      <td>Good grounding book in strategy</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14177</td>\n",
       "      <td>super excellent cd player with remote control/...</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>597945</td>\n",
       "      <td>I work in the healthcare field and have seen q...</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>9786</td>\n",
       "      <td>I have a miniature poodle puppy who eats every...</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>606221</td>\n",
       "      <td>I wasnt a big fan of this book. it didnt keep ...</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>30590</td>\n",
       "      <td>This movie has one the best performances by Ja...</td>\n",
       "      <td>dvd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>9038</td>\n",
       "      <td>Quick delivery. Reasonable price. Item could n...</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                               text       domain\n",
       "0       12429  the ease and timelyness of the product was ver...  electronics\n",
       "1      813196  I'm a man about to turn 50 with 4 yr. olds twi...        books\n",
       "2      527488  There is tons to do in Washington DC and despi...        books\n",
       "3      701823                    Good grounding book in strategy        books\n",
       "4       14177  super excellent cd player with remote control/...  electronics\n",
       "...       ...                                                ...          ...\n",
       "15995  597945  I work in the healthcare field and have seen q...        books\n",
       "15996    9786  I have a miniature poodle puppy who eats every...      kitchen\n",
       "15997  606221  I wasnt a big fan of this book. it didnt keep ...        books\n",
       "15998   30590  This movie has one the best performances by Ja...          dvd\n",
       "15999    9038  Quick delivery. Reasonable price. Item could n...      kitchen\n",
       "\n",
       "[16000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_df = pd.read_json(os.path.join(save_dir, 'MDSD_unlabeled.json'))\n",
    "unlabeled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training용 데이터셋\n",
    "#### for MLM\n",
    "* 도메인 2개 (파일명에 알파벳 순으로 기재)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books&electronics_MLM_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_dvd&electronics_MLM_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_electronics&kitchen_MLM_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books&dvd_MLM_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books&kitchen_MLM_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_dvd&kitchen_MLM_for_post.txt\n"
     ]
    }
   ],
   "source": [
    "def mask_keywords(doc, keywords):\n",
    "    words = doc.split()\n",
    "    for i in range(len(words)):\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in words[i].lower():\n",
    "                words[i] = '[UNK]'\n",
    "    return ' '.join(words)\n",
    "\n",
    "def create_txt_for_post_training(docs, save_filepath, num_of_duplicates=10):    \n",
    "    with open(save_filepath, 'w') as output_file:\n",
    "        for _ in range(num_of_duplicates): # each sentence in the target domain gets duplicated 10 times\n",
    "            for doc_idx, doc in enumerate(docs):\n",
    "                output_file.write('{}\\n\\n'.format(doc))\n",
    "        output_file.write('[EOD]')\n",
    "    print(f'Created {save_filepath}')\n",
    "    \n",
    "mode = 'MLM'\n",
    "    \n",
    "domains = unlabeled_df.domain.unique()\n",
    "for (domain1, domain2) in list(combinations(domains, 2)):\n",
    "    moniker = '&'.join(sorted([domain1, domain2]))\n",
    "    df = copy.copy(unlabeled_df[unlabeled_df['domain'].isin([domain1, domain2])])\n",
    "    docs = df['text'].values\n",
    "    \n",
    "    save_filepath = os.path.join(save_dir, 'MDSD_{}_{}_for_post.txt'.format('&'.join(sorted([domain1, domain2])), mode))\n",
    "    create_txt_for_post_training(docs, save_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for DDT (Domain Distinguish Task)\n",
    "* 소스 도메인, 타겟 도메인 구분되어야 함\n",
    "    - TargetDomain: 1,000 pairs \n",
    "    - MixDomain: 1,000 pairs\n",
    "\n",
    "> 50% of time sentence A and sentence B are all randomly sampled from target domain reviews, we label it TargetDomain. And 50% of time sentence A and sentence B come from target domain and another domain, whose label is MixDomain. We do not fix the collocation, in another word, we only ensure that the two sentences come from different domains but the order is random. \n",
    "```\n",
    "Input = [CLS] The mouse is smooth and great [SEP] The screen is plain [SEP]\n",
    "Label = TargetDomain\n",
    "Input = [CLS] This book is boring [SEP] The system of the laptop is stable [SEP]\n",
    "Label = MixDomain\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 346.04it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 312.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_electronics->books_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 320.47it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 265.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_electronics->dvd_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 393.84it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 413.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_electronics->kitchen_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 352.45it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 391.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books->electronics_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 292.70it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 273.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books->dvd_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 345.56it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 431.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books->kitchen_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 309.61it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 381.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_dvd->electronics_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 289.65it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 315.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_dvd->books_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 326.88it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 421.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_dvd->kitchen_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 392.70it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 378.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_kitchen->electronics_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 361.68it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 307.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_kitchen->books_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 327.33it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 267.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_kitchen->dvd_DDT_for_post.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_sentence_pair_df(label, df1, df2, num_pairs):\n",
    "    def pick_one_sentence(df):\n",
    "        while True:\n",
    "            doc = df.iloc[np.random.randint(0, len(df))]['text']\n",
    "            sentences = sent_tokenize(doc)\n",
    "            \n",
    "            # 11개 이상의 단어를 가진 문장만을 대상으로.\n",
    "            sentences = [sent for sent in sentences if len(word_tokenize(sent)) > 10]\n",
    "            if len(sentences) > 0:\n",
    "                break\n",
    "                \n",
    "        idx = np.random.randint(0, len(sentences))\n",
    "        return sentences[idx]\n",
    "\n",
    "    records = []\n",
    "    for _ in tqdm(range(num_pairs)):\n",
    "        sent1 = pick_one_sentence(df1)\n",
    "        sent2 = pick_one_sentence(df2)\n",
    "        records.append((label, '[CLS] {} [SEP] {} [SEP]'.format(*shuffle([sent1, sent2]))))\n",
    "    \n",
    "    return pd.DataFrame(records, columns=['label', 'sentence_pair'])\n",
    "\n",
    "mode = 'DDT'\n",
    "\n",
    "domains = unlabeled_df.domain.unique()\n",
    "for source_domain in domains:\n",
    "    for target_domain in [d for d in domains if d!=source_domain]:\n",
    "        \n",
    "        source_df = unlabeled_df[unlabeled_df['domain']==source_domain]\n",
    "        target_df = unlabeled_df[unlabeled_df['domain']==target_domain]\n",
    "\n",
    "        mix_df = create_sentence_pair_df('MixDomain', source_df, target_df, num_pairs=1000)\n",
    "        target_df = create_sentence_pair_df('TargetDomain', target_df, target_df, num_pairs=1000)\n",
    "        ddt_df = shuffle(pd.concat([mix_df, target_df])).reset_index()\n",
    "\n",
    "        save_filepath = os.path.join(save_dir, 'MDSD_{}_{}_for_post.json'.format('->'.join([source_domain, target_domain]), mode))\n",
    "        ddt_df.to_json(save_filepath)\n",
    "        print(f'Created {save_filepath}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtext",
   "language": "python",
   "name": "torchtext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
