{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, random\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from itertools import combinations \n",
    "import re, copy\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdsd_labeled_filepaths = glob('/media/dmlab/My Passport/DATA/BenchmarkDataset/MDSD/*_labeled_*.csv')\n",
    "mdsd_unlabeled_filepaths = glob('/media/dmlab/My Passport/DATA/BenchmarkDataset/MDSD/*_unlabeled_*.csv')\n",
    "domain_cls_filepaths = glob('/media/dmlab/My Passport/DATA/cross-domain/domain-cls/*&*/target_labeled_*.csv')\n",
    "save_dir = '/media/dmlab/My Passport/DATA/cross-domain/data'\n",
    "if not os.path.exists(save_dir): os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4,000 unlabeled reviews per domain\n",
    "* 2,000 labeled reviews per domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[books] Droped 477734 rows having duplicated text\n",
      "[dvd] Droped 39540 rows having duplicated text\n",
      "[electronics] Droped 2213 rows having duplicated text\n",
      "[kitchen] Droped 1218 rows having duplicated text\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_unlabeled.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_labeled.json\n"
     ]
    }
   ],
   "source": [
    "def concat_dataframes(filepaths, drop_duplicates=True, sample_num=4000):\n",
    "    dfs = []\n",
    "    for filepath in filepaths:\n",
    "        df = pd.read_csv(filepath)\n",
    "        domain = os.path.basename(filepath).split('_')[0]\n",
    "        df['domain'] = domain\n",
    "        original_len = len(df)\n",
    "        if drop_duplicates:\n",
    "            df.drop_duplicates(['text'], keep='last', inplace=True)   # 중복된 텍스트 제거\n",
    "            print('[{}] Droped {} rows having duplicated text'.format(domain, original_len-len(df)))\n",
    "        if sample_num is not None:\n",
    "            df = df.sample(n=sample_num)   # 4000개 데이터만 랜덤하게 선택\n",
    "        dfs.append(df)\n",
    "    concat_df = pd.concat(dfs)\n",
    "    concat_df = shuffle(concat_df)   # Shuffle\n",
    "    concat_df.reset_index(inplace=True)   # Reset index\n",
    "    return concat_df\n",
    "\n",
    "unlabeled_df = concat_dataframes(mdsd_unlabeled_filepaths)\n",
    "filepath = os.path.join(save_dir, 'MDSD_unlabeled.json')\n",
    "unlabeled_df.to_json(filepath)\n",
    "print('Created {}'.format(filepath))\n",
    "\n",
    "labeled_df = concat_dataframes(mdsd_labeled_filepaths, drop_duplicates=False, sample_num=None)\n",
    "filepath = os.path.join(save_dir, 'MDSD_labeled.json')\n",
    "labeled_df.to_json(filepath)\n",
    "print('Created {}'.format(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>574</td>\n",
       "      <td>This Bluetooth remote device works as advertiz...</td>\n",
       "      <td>positive</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1822</td>\n",
       "      <td>I almost threw this coffee maker across my liv...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1669</td>\n",
       "      <td>This edition of the film sucks and sucks again...</td>\n",
       "      <td>negative</td>\n",
       "      <td>dvd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1147</td>\n",
       "      <td>The flight into New York had been a long one; ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>dvd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1074</td>\n",
       "      <td>I can't believe I spent good money on this vac...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>107</td>\n",
       "      <td>This is an awesome tablet! It has great pressu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>1649</td>\n",
       "      <td>I bought this cable to connect 50\" Plasma TV t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>1400</td>\n",
       "      <td>My timer didn't work either. It arrived broken...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>912</td>\n",
       "      <td>Everything works great. The only marginal issu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>738</td>\n",
       "      <td>This is the best - snaps on easily, cleans eas...</td>\n",
       "      <td>positive</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label  \\\n",
       "0       574  This Bluetooth remote device works as advertiz...  positive   \n",
       "1      1822  I almost threw this coffee maker across my liv...  negative   \n",
       "2      1669  This edition of the film sucks and sucks again...  negative   \n",
       "3      1147  The flight into New York had been a long one; ...  negative   \n",
       "4      1074  I can't believe I spent good money on this vac...  negative   \n",
       "...     ...                                                ...       ...   \n",
       "7995    107  This is an awesome tablet! It has great pressu...  positive   \n",
       "7996   1649  I bought this cable to connect 50\" Plasma TV t...  negative   \n",
       "7997   1400  My timer didn't work either. It arrived broken...  negative   \n",
       "7998    912  Everything works great. The only marginal issu...  positive   \n",
       "7999    738  This is the best - snaps on easily, cleans eas...  positive   \n",
       "\n",
       "           domain  \n",
       "0     electronics  \n",
       "1         kitchen  \n",
       "2             dvd  \n",
       "3             dvd  \n",
       "4         kitchen  \n",
       "...           ...  \n",
       "7995  electronics  \n",
       "7996  electronics  \n",
       "7997      kitchen  \n",
       "7998  electronics  \n",
       "7999      kitchen  \n",
       "\n",
       "[8000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df = pd.read_json(os.path.join(save_dir, 'MDSD_labeled.json'))\n",
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97230</td>\n",
       "      <td>After reading the review below, I have got to ...</td>\n",
       "      <td>dvd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8352</td>\n",
       "      <td>After step 8 of adding your songs to the Virgi...</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16895</td>\n",
       "      <td>I transfered video directly to the DVD with 15...</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>638090</td>\n",
       "      <td>Noble physics laureate Abdus Salam calls this ...</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5980</td>\n",
       "      <td>I have purchased several wine openers over the...</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>11102</td>\n",
       "      <td>Firstly this is my first purchase through Amaz...</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>386447</td>\n",
       "      <td>The last time I bought this was the Second Edi...</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>91833</td>\n",
       "      <td>I bought this for my Best Friend who is a Full...</td>\n",
       "      <td>dvd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>8122</td>\n",
       "      <td>I really wanted to love this little player and...</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>961638</td>\n",
       "      <td>This is one of my favourite fictional works ev...</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                               text       domain\n",
       "0       97230  After reading the review below, I have got to ...          dvd\n",
       "1        8352  After step 8 of adding your songs to the Virgi...  electronics\n",
       "2       16895  I transfered video directly to the DVD with 15...  electronics\n",
       "3      638090  Noble physics laureate Abdus Salam calls this ...        books\n",
       "4        5980  I have purchased several wine openers over the...      kitchen\n",
       "...       ...                                                ...          ...\n",
       "15995   11102  Firstly this is my first purchase through Amaz...  electronics\n",
       "15996  386447  The last time I bought this was the Second Edi...        books\n",
       "15997   91833  I bought this for my Best Friend who is a Full...          dvd\n",
       "15998    8122  I really wanted to love this little player and...  electronics\n",
       "15999  961638  This is one of my favourite fictional works ev...        books\n",
       "\n",
       "[16000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_df = pd.read_json(os.path.join(save_dir, 'MDSD_unlabeled.json'))\n",
    "unlabeled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training용 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_txt_for_post_training(docs, save_filepath, num_of_duplicates=10):    \n",
    "    with open(save_filepath, 'w') as output_file:\n",
    "        for _ in range(num_of_duplicates): # each sentence in the target domain gets duplicated 10 times\n",
    "            for doc_idx, doc in enumerate(docs):\n",
    "                output_file.write('{}\\n\\n'.format(doc))\n",
    "        output_file.write('[EOD]')\n",
    "    print(f'Created {save_filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline: Source+Target MLM\n",
    "* 도메인 2개 (파일명에 알파벳 순으로 기재)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_dvd&electronics_ST_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books&dvd_ST_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_dvd&kitchen_ST_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books&electronics_ST_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_electronics&kitchen_ST_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books&kitchen_ST_for_post.txt\n"
     ]
    }
   ],
   "source": [
    "mode = 'ST'\n",
    "    \n",
    "domains = unlabeled_df.domain.unique()\n",
    "for (domain1, domain2) in list(combinations(domains, 2)):\n",
    "    df = copy.copy(unlabeled_df[unlabeled_df['domain'].isin([domain1, domain2])])\n",
    "    docs = df['text'].values\n",
    "    \n",
    "    save_filepath = os.path.join(save_dir, 'MDSD_{}_{}_for_post.txt'.format('&'.join(sorted([domain1, domain2])), mode))\n",
    "    create_txt_for_post_training(docs, save_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline: Target MLM\n",
    "* 도메인 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_dvd_T_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_electronics_T_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_books_T_for_post.txt\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_kitchen_T_for_post.txt\n"
     ]
    }
   ],
   "source": [
    "mode = 'T'\n",
    "    \n",
    "domains = unlabeled_df.domain.unique()\n",
    "for domain1 in domains:\n",
    "    df = copy.copy(unlabeled_df[unlabeled_df['domain'].isin([domain1])])\n",
    "    docs = df['text'].values\n",
    "    \n",
    "    save_filepath = os.path.join(save_dir, 'MDSD_{}_{}_for_post.txt'.format(domain1, mode))\n",
    "    create_txt_for_post_training(docs, save_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposed: Similar Source + Target MLM\n",
    "* 타겟 labeled와 유사한 소스 unlabeled 텍스트를 수집 \n",
    "* 소스와 타겟 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source=dvd, Target=books, Number of similar texts=884\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=dvd-target=books_SimST_for_post.txt\n",
      "Source=books, Target=dvd, Number of similar texts=816\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=books-target=dvd_SimST_for_post.txt\n",
      "Source=electronics, Target=books, Number of similar texts=744\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=electronics-target=books_SimST_for_post.txt\n",
      "Source=books, Target=electronics, Number of similar texts=684\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=books-target=electronics_SimST_for_post.txt\n",
      "Source=kitchen, Target=books, Number of similar texts=742\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=kitchen-target=books_SimST_for_post.txt\n",
      "Source=books, Target=kitchen, Number of similar texts=654\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=books-target=kitchen_SimST_for_post.txt\n",
      "Source=electronics, Target=dvd, Number of similar texts=769\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=electronics-target=dvd_SimST_for_post.txt\n",
      "Source=dvd, Target=electronics, Number of similar texts=745\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=dvd-target=electronics_SimST_for_post.txt\n",
      "Source=kitchen, Target=dvd, Number of similar texts=741\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=kitchen-target=dvd_SimST_for_post.txt\n",
      "Source=dvd, Target=kitchen, Number of similar texts=716\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=dvd-target=kitchen_SimST_for_post.txt\n",
      "Source=kitchen, Target=electronics, Number of similar texts=873\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=kitchen-target=electronics_SimST_for_post.txt\n",
      "Source=electronics, Target=kitchen, Number of similar texts=895\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/data/MDSD_source=electronics-target=kitchen_SimST_for_post.txt\n"
     ]
    }
   ],
   "source": [
    "mode = 'SimST'\n",
    "\n",
    "for filepath in domain_cls_filepaths:\n",
    "    target_domain = os.path.basename(filepath).split('_')[-1].replace('.csv', '')\n",
    "    source_domain = os.path.basename(os.path.dirname(filepath)).replace(target_domain, '').replace('&', '')\n",
    "    df = pd.read_csv(filepath)\n",
    "    docs = df['most-similar_text'].unique()\n",
    "    print('Source={}, Target={}, Number of similar texts={}'.format(source_domain, target_domain, len(docs)))\n",
    "    \n",
    "    save_filepath = os.path.join(save_dir, 'MDSD_source={}-target={}_{}_for_post.txt'.format(source_domain, target_domain, mode))\n",
    "    create_txt_for_post_training(docs, save_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtext",
   "language": "python",
   "name": "torchtext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
