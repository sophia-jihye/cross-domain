{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from itertools import combinations \n",
    "from nltk.corpus import stopwords as stopwords_nltk \n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import re\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob('/media/dmlab/My Passport/DATA/BenchmarkDataset/MDSD/*_labeled_2000.csv')\n",
    "save_dir = '/media/dmlab/My Passport/DATA/cross-domain'\n",
    "train_val_dir = os.path.join(save_dir, 'train&val')\n",
    "if not os.path.exists(train_val_dir): os.makedirs(train_val_dir)\n",
    "kfold_train_val_dir = os.path.join(save_dir, 'kfold_train&val')\n",
    "if not os.path.exists(kfold_train_val_dir): os.makedirs(kfold_train_val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmlab/anaconda3/envs/torchtext/lib/python3.6/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "MULTIPLE_SPACES = re.compile(' +', re.UNICODE)\n",
    "removal_list = \"|,‘, ’, ◇, ‘, ”,  ’, ·, \\“, ·, △, ➤, ●,  , ■, (, ), \\\", >>, `, /, -,∼,=,ㆍ<,>, ?, !,【,】, …, ◆,%\"\n",
    "stopwords = stopwords_nltk.words('english')\n",
    "def get_preprocessed_tokens(text):\n",
    "    text = text.translate(str.maketrans(removal_list, ' '*len(removal_list)))   # 특수문자 제거\n",
    "    text = re.sub(MULTIPLE_SPACES, ' ', text)   # 무의미한 공백 제거\n",
    "    words = word_tokenize(text.lower())   # 소문자로 변경 후 tokenization\n",
    "    nouns = [token for token, tag in pos_tag(words) if tag in ['NN', 'NNS', 'NNP', 'NNPS']]   # 명사 추출\n",
    "    nouns = [lemmatizer.lemmatize(token) for token in nouns]   # lemmatization (e.g., movies -> movie)\n",
    "    nouns = [token for token in nouns if token not in stopwords]   # 불용어 제거\n",
    "    nouns = [token for token in nouns if len(token)>1]   # 길이가 1 이하인 단어 제거\n",
    "    return nouns\n",
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[books] Droped 18 rows having duplicated text\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b8d6fd44ea4077bd9939fc9c4cfd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1982 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dvd] Droped 33 rows having duplicated text\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65791190cf714327a6dcaf80908cf8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1967 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[electronics] Droped 39 rows having duplicated text\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48826216ee74461e9bc17f3be0fb99c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1961 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kitchen] Droped 23 rows having duplicated text\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd14d8544ddf425e9ed65ab15c41bc8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridget Jones, modern day woman, brillant and ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[bridget, jones, day, woman, brillant, acciden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[copy, school, principal, assistant, principal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a casual piano player and a Broadway fanati...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[piano, player, broadway, song, avenue, book, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[biography, author, lot, time, effort, work, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[book, year, flight, philosophy, money, month,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>I purchased this toy for a friend's dog a whil...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[toy, friend, dog, dog, quack, quack, toy, add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>I received the first topper and it was not sat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[topper, etc, pad, box]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Some how my previous review text got a little ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[review, text, thing, knife, cut, manufacture,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Ditto the other's observations... The thermost...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[observation, thermostat, temperature, unit, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>The thermometer of this heater is completely m...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[thermometer, heater, room, temperature, tempe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7887 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label   domain  \\\n",
       "0     Bridget Jones, modern day woman, brillant and ...  positive    books   \n",
       "1     I am ordering copies for all 23 middle school ...  positive    books   \n",
       "2     As a casual piano player and a Broadway fanati...  positive    books   \n",
       "3     This is one of the best biographies I have eve...  positive    books   \n",
       "4     I read this book many, many years ago on a ver...  positive    books   \n",
       "...                                                 ...       ...      ...   \n",
       "1995  I purchased this toy for a friend's dog a whil...  negative  kitchen   \n",
       "1996  I received the first topper and it was not sat...  negative  kitchen   \n",
       "1997  Some how my previous review text got a little ...  negative  kitchen   \n",
       "1998  Ditto the other's observations... The thermost...  negative  kitchen   \n",
       "1999  The thermometer of this heater is completely m...  negative  kitchen   \n",
       "\n",
       "                                                  nouns  \n",
       "0     [bridget, jones, day, woman, brillant, acciden...  \n",
       "1     [copy, school, principal, assistant, principal...  \n",
       "2     [piano, player, broadway, song, avenue, book, ...  \n",
       "3     [biography, author, lot, time, effort, work, l...  \n",
       "4     [book, year, flight, philosophy, money, month,...  \n",
       "...                                                 ...  \n",
       "1995  [toy, friend, dog, dog, quack, quack, toy, add...  \n",
       "1996                            [topper, etc, pad, box]  \n",
       "1997  [review, text, thing, knife, cut, manufacture,...  \n",
       "1998  [observation, thermostat, temperature, unit, r...  \n",
       "1999  [thermometer, heater, room, temperature, tempe...  \n",
       "\n",
       "[7887 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for filepath in filepaths:\n",
    "    df = pd.read_csv(filepath)\n",
    "    domain = os.path.basename(filepath).split('_')[0]\n",
    "    df['domain'] = domain\n",
    "\n",
    "    original_len = len(df)\n",
    "    df.drop_duplicates(['text'], keep='last', inplace=True)   # 중복된 제목 제거\n",
    "    print('[{}] Droped {} rows having duplicated text'.format(domain, original_len-len(df)))\n",
    "    df['nouns'] = df.progress_apply(lambda x: get_preprocessed_tokens(x['text']), axis=1)   # 전처리 함수 실행\n",
    "    dfs.append(df)\n",
    "raw_df = pd.concat(dfs)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword 추출 using KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520f33e900d8496c9fe8edc3aeecaa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "      <th>nouns</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridget Jones, modern day woman, brillant and ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[bridget, jones, day, woman, brillant, acciden...</td>\n",
       "      <td>[bridget, book, woman, chick, brillant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[copy, school, principal, assistant, principal...</td>\n",
       "      <td>[einstein, philosophy, wheatley]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a casual piano player and a Broadway fanati...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[piano, player, broadway, song, avenue, book, ...</td>\n",
       "      <td>[piano, broadway, sonata, avenue]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[biography, author, lot, time, effort, work, l...</td>\n",
       "      <td>[francis, book]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[book, year, flight, philosophy, money, month,...</td>\n",
       "      <td>[millionaire, philosophy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>I purchased this toy for a friend's dog a whil...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[toy, friend, dog, dog, quack, quack, toy, add...</td>\n",
       "      <td>[toy, dog, stuffing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>I received the first topper and it was not sat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[topper, etc, pad, box]</td>\n",
       "      <td>[topper, box]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Some how my previous review text got a little ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[review, text, thing, knife, cut, manufacture,...</td>\n",
       "      <td>[quality, cut, manufacture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Ditto the other's observations... The thermost...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[observation, thermostat, temperature, unit, r...</td>\n",
       "      <td>[thermostat, temperature]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>The thermometer of this heater is completely m...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[thermometer, heater, room, temperature, tempe...</td>\n",
       "      <td>[thermometer, temperature, heater]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7887 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label   domain  \\\n",
       "0     Bridget Jones, modern day woman, brillant and ...  positive    books   \n",
       "1     I am ordering copies for all 23 middle school ...  positive    books   \n",
       "2     As a casual piano player and a Broadway fanati...  positive    books   \n",
       "3     This is one of the best biographies I have eve...  positive    books   \n",
       "4     I read this book many, many years ago on a ver...  positive    books   \n",
       "...                                                 ...       ...      ...   \n",
       "1995  I purchased this toy for a friend's dog a whil...  negative  kitchen   \n",
       "1996  I received the first topper and it was not sat...  negative  kitchen   \n",
       "1997  Some how my previous review text got a little ...  negative  kitchen   \n",
       "1998  Ditto the other's observations... The thermost...  negative  kitchen   \n",
       "1999  The thermometer of this heater is completely m...  negative  kitchen   \n",
       "\n",
       "                                                  nouns  \\\n",
       "0     [bridget, jones, day, woman, brillant, acciden...   \n",
       "1     [copy, school, principal, assistant, principal...   \n",
       "2     [piano, player, broadway, song, avenue, book, ...   \n",
       "3     [biography, author, lot, time, effort, work, l...   \n",
       "4     [book, year, flight, philosophy, money, month,...   \n",
       "...                                                 ...   \n",
       "1995  [toy, friend, dog, dog, quack, quack, toy, add...   \n",
       "1996                            [topper, etc, pad, box]   \n",
       "1997  [review, text, thing, knife, cut, manufacture,...   \n",
       "1998  [observation, thermostat, temperature, unit, r...   \n",
       "1999  [thermometer, heater, room, temperature, tempe...   \n",
       "\n",
       "                                     keywords  \n",
       "0     [bridget, book, woman, chick, brillant]  \n",
       "1            [einstein, philosophy, wheatley]  \n",
       "2           [piano, broadway, sonata, avenue]  \n",
       "3                             [francis, book]  \n",
       "4                   [millionaire, philosophy]  \n",
       "...                                       ...  \n",
       "1995                     [toy, dog, stuffing]  \n",
       "1996                            [topper, box]  \n",
       "1997              [quality, cut, manufacture]  \n",
       "1998                [thermostat, temperature]  \n",
       "1999       [thermometer, temperature, heater]  \n",
       "\n",
       "[7887 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['keywords'] = raw_df.progress_apply(lambda x: [word for (word, score) in kw_model.extract_keywords(x['text']) if word in x['nouns']], axis=1)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maskted_text: 모든 keyword masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2005a787a7c148028f16fd15ced730c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "      <th>nouns</th>\n",
       "      <th>keywords</th>\n",
       "      <th>masked_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridget Jones, modern day woman, brillant and ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[bridget, jones, day, woman, brillant, acciden...</td>\n",
       "      <td>[bridget, book, woman, chick, brillant]</td>\n",
       "      <td>[UNK] Jones, modern day [UNK], [UNK] and doesn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[copy, school, principal, assistant, principal...</td>\n",
       "      <td>[einstein, philosophy, wheatley]</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a casual piano player and a Broadway fanati...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[piano, player, broadway, song, avenue, book, ...</td>\n",
       "      <td>[piano, broadway, sonata, avenue]</td>\n",
       "      <td>As a casual [UNK] player and a [UNK] fanatic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[biography, author, lot, time, effort, work, l...</td>\n",
       "      <td>[francis, book]</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[book, year, flight, philosophy, money, month,...</td>\n",
       "      <td>[millionaire, philosophy]</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>I purchased this toy for a friend's dog a whil...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[toy, friend, dog, dog, quack, quack, toy, add...</td>\n",
       "      <td>[toy, dog, stuffing]</td>\n",
       "      <td>I purchased this [UNK] for a friend's [UNK] a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>I received the first topper and it was not sat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[topper, etc, pad, box]</td>\n",
       "      <td>[topper, box]</td>\n",
       "      <td>I received the first [UNK] and it was not sati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Some how my previous review text got a little ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[review, text, thing, knife, cut, manufacture,...</td>\n",
       "      <td>[quality, cut, manufacture]</td>\n",
       "      <td>Some how my previous review text got a little ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Ditto the other's observations... The thermost...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[observation, thermostat, temperature, unit, r...</td>\n",
       "      <td>[thermostat, temperature]</td>\n",
       "      <td>Ditto the other's observations... The [UNK] se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>The thermometer of this heater is completely m...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[thermometer, heater, room, temperature, tempe...</td>\n",
       "      <td>[thermometer, temperature, heater]</td>\n",
       "      <td>The [UNK] of this [UNK] is completely messed u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7887 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label   domain  \\\n",
       "0     Bridget Jones, modern day woman, brillant and ...  positive    books   \n",
       "1     I am ordering copies for all 23 middle school ...  positive    books   \n",
       "2     As a casual piano player and a Broadway fanati...  positive    books   \n",
       "3     This is one of the best biographies I have eve...  positive    books   \n",
       "4     I read this book many, many years ago on a ver...  positive    books   \n",
       "...                                                 ...       ...      ...   \n",
       "1995  I purchased this toy for a friend's dog a whil...  negative  kitchen   \n",
       "1996  I received the first topper and it was not sat...  negative  kitchen   \n",
       "1997  Some how my previous review text got a little ...  negative  kitchen   \n",
       "1998  Ditto the other's observations... The thermost...  negative  kitchen   \n",
       "1999  The thermometer of this heater is completely m...  negative  kitchen   \n",
       "\n",
       "                                                  nouns  \\\n",
       "0     [bridget, jones, day, woman, brillant, acciden...   \n",
       "1     [copy, school, principal, assistant, principal...   \n",
       "2     [piano, player, broadway, song, avenue, book, ...   \n",
       "3     [biography, author, lot, time, effort, work, l...   \n",
       "4     [book, year, flight, philosophy, money, month,...   \n",
       "...                                                 ...   \n",
       "1995  [toy, friend, dog, dog, quack, quack, toy, add...   \n",
       "1996                            [topper, etc, pad, box]   \n",
       "1997  [review, text, thing, knife, cut, manufacture,...   \n",
       "1998  [observation, thermostat, temperature, unit, r...   \n",
       "1999  [thermometer, heater, room, temperature, tempe...   \n",
       "\n",
       "                                     keywords  \\\n",
       "0     [bridget, book, woman, chick, brillant]   \n",
       "1            [einstein, philosophy, wheatley]   \n",
       "2           [piano, broadway, sonata, avenue]   \n",
       "3                             [francis, book]   \n",
       "4                   [millionaire, philosophy]   \n",
       "...                                       ...   \n",
       "1995                     [toy, dog, stuffing]   \n",
       "1996                            [topper, box]   \n",
       "1997              [quality, cut, manufacture]   \n",
       "1998                [thermostat, temperature]   \n",
       "1999       [thermometer, temperature, heater]   \n",
       "\n",
       "                                            masked_text  \n",
       "0     [UNK] Jones, modern day [UNK], [UNK] and doesn...  \n",
       "1     I am ordering copies for all 23 middle school ...  \n",
       "2     As a casual [UNK] player and a [UNK] fanatic, ...  \n",
       "3     This is one of the best biographies I have eve...  \n",
       "4     I read this book many, many years ago on a ver...  \n",
       "...                                                 ...  \n",
       "1995  I purchased this [UNK] for a friend's [UNK] a ...  \n",
       "1996  I received the first [UNK] and it was not sati...  \n",
       "1997  Some how my previous review text got a little ...  \n",
       "1998  Ditto the other's observations... The [UNK] se...  \n",
       "1999  The [UNK] of this [UNK] is completely messed u...  \n",
       "\n",
       "[7887 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mask_keywords(doc, keywords):\n",
    "    for to_be_masked in keywords:\n",
    "        doc = doc.replace(to_be_masked, '[UNK]')\n",
    "        doc = doc.replace(to_be_masked[0].upper()+to_be_masked[1:], '[UNK]')\n",
    "        doc = doc.replace(to_be_masked.upper(), '[UNK]')\n",
    "    return doc\n",
    "\n",
    "raw_df['masked_text'] = raw_df.progress_apply(lambda x: mask_keywords(x['text'], x['keywords']), axis=1)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "domain-specific feature: KeyBERT로 추출한 keywords에 한해, source or target 등장비율이 0.7이상인 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/MDSD_keywords.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>books</th>\n",
       "      <th>dvd</th>\n",
       "      <th>electronics</th>\n",
       "      <th>kitchen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>printer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>ipod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>card</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>tv</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>dvd</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword  books  dvd  electronics  kitchen\n",
       "2192  printer      0    0           94        0\n",
       "5417     ipod      0    0           93        2\n",
       "6471     card      0    0           86        1\n",
       "4803       tv      1   14           85        3\n",
       "2287      dvd      2  256           84        1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_freq_of_one_domain(raw_df, domain, keyword):\n",
    "    _df = raw_df[raw_df['domain']==domain]\n",
    "    _df = _df[_df['keywords'].apply(lambda x: keyword in x)]\n",
    "    return len(_df)\n",
    "\n",
    "keywords_set = set([k for sub in raw_df.keywords for k in sub])\n",
    "keywords_df = pd.DataFrame(keywords_set, columns=['keyword'])\n",
    "for domain in raw_df.domain.unique():\n",
    "    keywords_df[domain] = keywords_df['keyword'].progress_apply(lambda x: get_freq_of_one_domain(raw_df, domain, x))\n",
    "\n",
    "keywords_df.to_csv(os.path.join(save_dir, 'MDSD_keywords.csv'), index=False)\n",
    "print('Created {}'.format(os.path.join(save_dir, 'MDSD_keywords.csv')))\n",
    "\n",
    "keywords_df.sort_values(by=['electronics'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7887/7887 [00:10<00:00, 763.99it/s]\n",
      "/home/dmlab/anaconda3/envs/torchtext/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "100%|██████████| 7887/7887 [00:10<00:00, 778.31it/s] \n",
      "100%|██████████| 7887/7887 [00:09<00:00, 803.16it/s]  \n",
      "100%|██████████| 7887/7887 [00:10<00:00, 773.83it/s]  \n",
      "100%|██████████| 7887/7887 [00:09<00:00, 796.56it/s]  \n",
      "100%|██████████| 7887/7887 [00:09<00:00, 800.97it/s]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "      <th>nouns</th>\n",
       "      <th>keywords</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>masked_text_books&amp;dvd</th>\n",
       "      <th>masked_text_books&amp;electronics</th>\n",
       "      <th>masked_text_books&amp;kitchen</th>\n",
       "      <th>masked_text_dvd&amp;electronics</th>\n",
       "      <th>masked_text_dvd&amp;kitchen</th>\n",
       "      <th>masked_text_electronics&amp;kitchen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bridget Jones, modern day woman, brillant and ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[bridget, jones, day, woman, brillant, acciden...</td>\n",
       "      <td>[bridget, book, woman, chick, brillant]</td>\n",
       "      <td>[UNK] Jones, modern day [UNK], [UNK] and doesn...</td>\n",
       "      <td>[UNK] Jones, modern day woman, [UNK] and doesn...</td>\n",
       "      <td>[UNK] Jones, modern day [UNK], [UNK] and doesn...</td>\n",
       "      <td>[UNK] Jones, modern day [UNK], [UNK] and doesn...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[copy, school, principal, assistant, principal...</td>\n",
       "      <td>[einstein, philosophy, wheatley]</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>As a casual piano player and a Broadway fanati...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[piano, player, broadway, song, avenue, book, ...</td>\n",
       "      <td>[piano, broadway, sonata, avenue]</td>\n",
       "      <td>As a casual [UNK] player and a [UNK] fanatic, ...</td>\n",
       "      <td>As a casual [UNK] player and a Broadway fanati...</td>\n",
       "      <td>As a casual piano player and a [UNK] fanatic, ...</td>\n",
       "      <td>As a casual [UNK] player and a [UNK] fanatic, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[biography, author, lot, time, effort, work, l...</td>\n",
       "      <td>[francis, book]</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[book, year, flight, philosophy, money, month,...</td>\n",
       "      <td>[millionaire, philosophy]</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text     label domain  \\\n",
       "0      0  Bridget Jones, modern day woman, brillant and ...  positive  books   \n",
       "1      1  I am ordering copies for all 23 middle school ...  positive  books   \n",
       "2      2  As a casual piano player and a Broadway fanati...  positive  books   \n",
       "3      3  This is one of the best biographies I have eve...  positive  books   \n",
       "4      4  I read this book many, many years ago on a ver...  positive  books   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  [bridget, jones, day, woman, brillant, acciden...   \n",
       "1  [copy, school, principal, assistant, principal...   \n",
       "2  [piano, player, broadway, song, avenue, book, ...   \n",
       "3  [biography, author, lot, time, effort, work, l...   \n",
       "4  [book, year, flight, philosophy, money, month,...   \n",
       "\n",
       "                                  keywords  \\\n",
       "0  [bridget, book, woman, chick, brillant]   \n",
       "1         [einstein, philosophy, wheatley]   \n",
       "2        [piano, broadway, sonata, avenue]   \n",
       "3                          [francis, book]   \n",
       "4                [millionaire, philosophy]   \n",
       "\n",
       "                                         masked_text  \\\n",
       "0  [UNK] Jones, modern day [UNK], [UNK] and doesn...   \n",
       "1  I am ordering copies for all 23 middle school ...   \n",
       "2  As a casual [UNK] player and a [UNK] fanatic, ...   \n",
       "3  This is one of the best biographies I have eve...   \n",
       "4  I read this book many, many years ago on a ver...   \n",
       "\n",
       "                               masked_text_books&dvd  \\\n",
       "0  [UNK] Jones, modern day woman, [UNK] and doesn...   \n",
       "1  I am ordering copies for all 23 middle school ...   \n",
       "2  As a casual [UNK] player and a Broadway fanati...   \n",
       "3  This is one of the best biographies I have eve...   \n",
       "4  I read this book many, many years ago on a ver...   \n",
       "\n",
       "                       masked_text_books&electronics  \\\n",
       "0  [UNK] Jones, modern day [UNK], [UNK] and doesn...   \n",
       "1  I am ordering copies for all 23 middle school ...   \n",
       "2  As a casual piano player and a [UNK] fanatic, ...   \n",
       "3  This is one of the best biographies I have eve...   \n",
       "4  I read this book many, many years ago on a ver...   \n",
       "\n",
       "                           masked_text_books&kitchen  \\\n",
       "0  [UNK] Jones, modern day [UNK], [UNK] and doesn...   \n",
       "1  I am ordering copies for all 23 middle school ...   \n",
       "2  As a casual [UNK] player and a [UNK] fanatic, ...   \n",
       "3  This is one of the best biographies I have eve...   \n",
       "4  I read this book many, many years ago on a ver...   \n",
       "\n",
       "  masked_text_dvd&electronics masked_text_dvd&kitchen  \\\n",
       "0                        None                    None   \n",
       "1                        None                    None   \n",
       "2                        None                    None   \n",
       "3                        None                    None   \n",
       "4                        None                    None   \n",
       "\n",
       "  masked_text_electronics&kitchen  \n",
       "0                            None  \n",
       "1                            None  \n",
       "2                            None  \n",
       "3                            None  \n",
       "4                            None  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_domain_specific_keyword(keyword, keywords_df, domain1, domain2, threshold=0.7):    \n",
    "    k_record = keywords_df[keywords_df['keyword']==keyword].iloc[0]\n",
    "    ratio_for_one_domain = k_record[domain1] / (k_record[domain1]+k_record[domain2])\n",
    "    return ratio_for_one_domain > threshold or ratio_for_one_domain < (1-threshold)\n",
    "\n",
    "for (domain1, domain2) in list(combinations(raw_df.domain.unique(), 2)):\n",
    "    raw_df['masked_text_{}&{}'.format(*sorted([domain1, domain2]))] = raw_df.progress_apply\\\n",
    "        (lambda x: mask_keywords(x['text'], [k for k in x['keywords'] \\\n",
    "        if is_domain_specific_keyword(k, keywords_df, domain1, domain2)]) \\\n",
    "         if x['domain'] in (domain1, domain2) else None, axis=1)\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "      <th>nouns</th>\n",
       "      <th>keywords</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>masked_text_books&amp;dvd</th>\n",
       "      <th>masked_text_books&amp;electronics</th>\n",
       "      <th>masked_text_books&amp;kitchen</th>\n",
       "      <th>masked_text_dvd&amp;electronics</th>\n",
       "      <th>masked_text_dvd&amp;kitchen</th>\n",
       "      <th>masked_text_electronics&amp;kitchen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bridget Jones, modern day woman, brillant and ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[bridget, jones, day, woman, brillant, acciden...</td>\n",
       "      <td>[bridget, book, woman, chick, brillant]</td>\n",
       "      <td>[UNK] Jones, modern day [UNK], [UNK] and doesn...</td>\n",
       "      <td>[UNK] Jones, modern day woman, [UNK] and doesn...</td>\n",
       "      <td>[UNK] Jones, modern day [UNK], [UNK] and doesn...</td>\n",
       "      <td>[UNK] Jones, modern day [UNK], [UNK] and doesn...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[copy, school, principal, assistant, principal...</td>\n",
       "      <td>[einstein, philosophy, wheatley]</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>I am ordering copies for all 23 middle school ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>As a casual piano player and a Broadway fanati...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[piano, player, broadway, song, avenue, book, ...</td>\n",
       "      <td>[piano, broadway, sonata, avenue]</td>\n",
       "      <td>As a casual [UNK] player and a [UNK] fanatic, ...</td>\n",
       "      <td>As a casual [UNK] player and a Broadway fanati...</td>\n",
       "      <td>As a casual piano player and a [UNK] fanatic, ...</td>\n",
       "      <td>As a casual [UNK] player and a [UNK] fanatic, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[biography, author, lot, time, effort, work, l...</td>\n",
       "      <td>[francis, book]</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>This is one of the best biographies I have eve...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>positive</td>\n",
       "      <td>books</td>\n",
       "      <td>[book, year, flight, philosophy, money, month,...</td>\n",
       "      <td>[millionaire, philosophy]</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>I read this book many, many years ago on a ver...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7882</th>\n",
       "      <td>7882</td>\n",
       "      <td>I purchased this toy for a friend's dog a whil...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[toy, friend, dog, dog, quack, quack, toy, add...</td>\n",
       "      <td>[toy, dog, stuffing]</td>\n",
       "      <td>I purchased this [UNK] for a friend's [UNK] a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I purchased this [UNK] for a friend's [UNK] a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>I purchased this [UNK] for a friend's [UNK] a ...</td>\n",
       "      <td>I purchased this [UNK] for a friend's [UNK] a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7883</th>\n",
       "      <td>7883</td>\n",
       "      <td>I received the first topper and it was not sat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[topper, etc, pad, box]</td>\n",
       "      <td>[topper, box]</td>\n",
       "      <td>I received the first [UNK] and it was not sati...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I received the first [UNK] and it was not sati...</td>\n",
       "      <td>None</td>\n",
       "      <td>I received the first [UNK] and it was not sati...</td>\n",
       "      <td>I received the first [UNK] and it was not sati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>7884</td>\n",
       "      <td>Some how my previous review text got a little ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[review, text, thing, knife, cut, manufacture,...</td>\n",
       "      <td>[quality, cut, manufacture]</td>\n",
       "      <td>Some how my previous review text got a little ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Some how my previous review text got a little ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Some how my previous review text got a little ...</td>\n",
       "      <td>Some how my previous review text got a little ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885</th>\n",
       "      <td>7885</td>\n",
       "      <td>Ditto the other's observations... The thermost...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[observation, thermostat, temperature, unit, r...</td>\n",
       "      <td>[thermostat, temperature]</td>\n",
       "      <td>Ditto the other's observations... The [UNK] se...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ditto the other's observations... The [UNK] se...</td>\n",
       "      <td>None</td>\n",
       "      <td>Ditto the other's observations... The [UNK] se...</td>\n",
       "      <td>Ditto the other's observations... The [UNK] se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7886</th>\n",
       "      <td>7886</td>\n",
       "      <td>The thermometer of this heater is completely m...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>[thermometer, heater, room, temperature, tempe...</td>\n",
       "      <td>[thermometer, temperature, heater]</td>\n",
       "      <td>The [UNK] of this [UNK] is completely messed u...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The [UNK] of this [UNK] is completely messed u...</td>\n",
       "      <td>None</td>\n",
       "      <td>The [UNK] of this [UNK] is completely messed u...</td>\n",
       "      <td>The [UNK] of this [UNK] is completely messed u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7887 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label  \\\n",
       "0         0  Bridget Jones, modern day woman, brillant and ...  positive   \n",
       "1         1  I am ordering copies for all 23 middle school ...  positive   \n",
       "2         2  As a casual piano player and a Broadway fanati...  positive   \n",
       "3         3  This is one of the best biographies I have eve...  positive   \n",
       "4         4  I read this book many, many years ago on a ver...  positive   \n",
       "...     ...                                                ...       ...   \n",
       "7882   7882  I purchased this toy for a friend's dog a whil...  negative   \n",
       "7883   7883  I received the first topper and it was not sat...  negative   \n",
       "7884   7884  Some how my previous review text got a little ...  negative   \n",
       "7885   7885  Ditto the other's observations... The thermost...  negative   \n",
       "7886   7886  The thermometer of this heater is completely m...  negative   \n",
       "\n",
       "       domain                                              nouns  \\\n",
       "0       books  [bridget, jones, day, woman, brillant, acciden...   \n",
       "1       books  [copy, school, principal, assistant, principal...   \n",
       "2       books  [piano, player, broadway, song, avenue, book, ...   \n",
       "3       books  [biography, author, lot, time, effort, work, l...   \n",
       "4       books  [book, year, flight, philosophy, money, month,...   \n",
       "...       ...                                                ...   \n",
       "7882  kitchen  [toy, friend, dog, dog, quack, quack, toy, add...   \n",
       "7883  kitchen                            [topper, etc, pad, box]   \n",
       "7884  kitchen  [review, text, thing, knife, cut, manufacture,...   \n",
       "7885  kitchen  [observation, thermostat, temperature, unit, r...   \n",
       "7886  kitchen  [thermometer, heater, room, temperature, tempe...   \n",
       "\n",
       "                                     keywords  \\\n",
       "0     [bridget, book, woman, chick, brillant]   \n",
       "1            [einstein, philosophy, wheatley]   \n",
       "2           [piano, broadway, sonata, avenue]   \n",
       "3                             [francis, book]   \n",
       "4                   [millionaire, philosophy]   \n",
       "...                                       ...   \n",
       "7882                     [toy, dog, stuffing]   \n",
       "7883                            [topper, box]   \n",
       "7884              [quality, cut, manufacture]   \n",
       "7885                [thermostat, temperature]   \n",
       "7886       [thermometer, temperature, heater]   \n",
       "\n",
       "                                            masked_text  \\\n",
       "0     [UNK] Jones, modern day [UNK], [UNK] and doesn...   \n",
       "1     I am ordering copies for all 23 middle school ...   \n",
       "2     As a casual [UNK] player and a [UNK] fanatic, ...   \n",
       "3     This is one of the best biographies I have eve...   \n",
       "4     I read this book many, many years ago on a ver...   \n",
       "...                                                 ...   \n",
       "7882  I purchased this [UNK] for a friend's [UNK] a ...   \n",
       "7883  I received the first [UNK] and it was not sati...   \n",
       "7884  Some how my previous review text got a little ...   \n",
       "7885  Ditto the other's observations... The [UNK] se...   \n",
       "7886  The [UNK] of this [UNK] is completely messed u...   \n",
       "\n",
       "                                  masked_text_books&dvd  \\\n",
       "0     [UNK] Jones, modern day woman, [UNK] and doesn...   \n",
       "1     I am ordering copies for all 23 middle school ...   \n",
       "2     As a casual [UNK] player and a Broadway fanati...   \n",
       "3     This is one of the best biographies I have eve...   \n",
       "4     I read this book many, many years ago on a ver...   \n",
       "...                                                 ...   \n",
       "7882                                               None   \n",
       "7883                                               None   \n",
       "7884                                               None   \n",
       "7885                                               None   \n",
       "7886                                               None   \n",
       "\n",
       "                          masked_text_books&electronics  \\\n",
       "0     [UNK] Jones, modern day [UNK], [UNK] and doesn...   \n",
       "1     I am ordering copies for all 23 middle school ...   \n",
       "2     As a casual piano player and a [UNK] fanatic, ...   \n",
       "3     This is one of the best biographies I have eve...   \n",
       "4     I read this book many, many years ago on a ver...   \n",
       "...                                                 ...   \n",
       "7882                                               None   \n",
       "7883                                               None   \n",
       "7884                                               None   \n",
       "7885                                               None   \n",
       "7886                                               None   \n",
       "\n",
       "                              masked_text_books&kitchen  \\\n",
       "0     [UNK] Jones, modern day [UNK], [UNK] and doesn...   \n",
       "1     I am ordering copies for all 23 middle school ...   \n",
       "2     As a casual [UNK] player and a [UNK] fanatic, ...   \n",
       "3     This is one of the best biographies I have eve...   \n",
       "4     I read this book many, many years ago on a ver...   \n",
       "...                                                 ...   \n",
       "7882  I purchased this [UNK] for a friend's [UNK] a ...   \n",
       "7883  I received the first [UNK] and it was not sati...   \n",
       "7884  Some how my previous review text got a little ...   \n",
       "7885  Ditto the other's observations... The [UNK] se...   \n",
       "7886  The [UNK] of this [UNK] is completely messed u...   \n",
       "\n",
       "     masked_text_dvd&electronics  \\\n",
       "0                           None   \n",
       "1                           None   \n",
       "2                           None   \n",
       "3                           None   \n",
       "4                           None   \n",
       "...                          ...   \n",
       "7882                        None   \n",
       "7883                        None   \n",
       "7884                        None   \n",
       "7885                        None   \n",
       "7886                        None   \n",
       "\n",
       "                                masked_text_dvd&kitchen  \\\n",
       "0                                                  None   \n",
       "1                                                  None   \n",
       "2                                                  None   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "7882  I purchased this [UNK] for a friend's [UNK] a ...   \n",
       "7883  I received the first [UNK] and it was not sati...   \n",
       "7884  Some how my previous review text got a little ...   \n",
       "7885  Ditto the other's observations... The [UNK] se...   \n",
       "7886  The [UNK] of this [UNK] is completely messed u...   \n",
       "\n",
       "                        masked_text_electronics&kitchen  \n",
       "0                                                  None  \n",
       "1                                                  None  \n",
       "2                                                  None  \n",
       "3                                                  None  \n",
       "4                                                  None  \n",
       "...                                                 ...  \n",
       "7882  I purchased this [UNK] for a friend's [UNK] a ...  \n",
       "7883  I received the first [UNK] and it was not sati...  \n",
       "7884  Some how my previous review text got a little ...  \n",
       "7885  Ditto the other's observations... The [UNK] se...  \n",
       "7886  The [UNK] of this [UNK] is completely messed u...  \n",
       "\n",
       "[7887 rows x 13 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(os.path.join(save_dir, 'MDSD_masked.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/MDSD_masked.json\n"
     ]
    }
   ],
   "source": [
    "# raw_df.reset_index(inplace=True)\n",
    "raw_df.to_json(os.path.join(save_dir, 'MDSD_masked.json'))\n",
    "print('Created {}'.format(os.path.join(save_dir, 'MDSD_masked.json')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training set, validation set 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/train&val/books_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/train&val/books_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/train&val/dvd_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/train&val/dvd_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/train&val/electronics_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/train&val/electronics_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/train&val/kitchen_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/train&val/kitchen_val.json\n"
     ]
    }
   ],
   "source": [
    "for domain in raw_df.domain.unique():\n",
    "    one_df = raw_df[raw_df['domain']==domain]\n",
    "    train_df, val_df = train_test_split(one_df, test_size=.2, shuffle=True, stratify=one_df['label'].values)\n",
    "    filepath = os.path.join(train_val_dir, '{}_train.json'.format(domain))\n",
    "    train_df.to_json(filepath)\n",
    "    print('Created {}'.format(filepath))\n",
    "    filepath = os.path.join(train_val_dir, '{}_val.json'.format(domain))\n",
    "    val_df.to_json(filepath)\n",
    "    print('Created {}'.format(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold set 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=0_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=0_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=0_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=1_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=1_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=1_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=2_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=2_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=2_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=3_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=3_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=3_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=4_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=4_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/books_k=4_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=0_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=0_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=0_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=1_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=1_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=1_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=2_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=2_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=2_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=3_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=3_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=3_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=4_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=4_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/dvd_k=4_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=0_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=0_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=0_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=1_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=1_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=1_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=2_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=2_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=2_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=3_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=3_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=3_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=4_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=4_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/electronics_k=4_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=0_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=0_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=0_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=1_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=1_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=1_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=2_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=2_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=2_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=3_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=3_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=3_test.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=4_train.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=4_val.json\n",
      "Created /media/dmlab/My Passport/DATA/cross-domain/kfold_train&val/kitchen_k=4_test.json\n"
     ]
    }
   ],
   "source": [
    "for domain in raw_df.domain.unique():\n",
    "    one_df = raw_df[raw_df['domain']==domain]\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5)\n",
    "    for i, (train_val_indices, test_indices) in enumerate(kf.split(one_df, one_df['label'].values)):\n",
    "        train_val_df = one_df.iloc[train_val_indices]\n",
    "        train_df, val_df = train_test_split(train_val_df, test_size=.2, shuffle=True, stratify=train_val_df['label'].values)\n",
    "        test_df = one_df.iloc[test_indices]\n",
    "    \n",
    "        filepath = os.path.join(kfold_train_val_dir, '{}_k={}_train.json'.format(domain, i))\n",
    "        train_df.to_json(filepath)\n",
    "        print('Created {}'.format(filepath))\n",
    "        filepath = os.path.join(kfold_train_val_dir, '{}_k={}_val.json'.format(domain, i))\n",
    "        val_df.to_json(filepath)\n",
    "        print('Created {}'.format(filepath))\n",
    "        filepath = os.path.join(kfold_train_val_dir, '{}_k={}_test.json'.format(domain, i))\n",
    "        test_df.to_json(filepath)\n",
    "        print('Created {}'.format(filepath))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtext",
   "language": "python",
   "name": "torchtext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
